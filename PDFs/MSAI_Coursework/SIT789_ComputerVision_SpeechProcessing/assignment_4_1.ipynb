{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1f12b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import os\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3570d908",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dictionary(object):\n",
    "    def __init__(self, name, img_filenames, num_words):\n",
    "        self.name = name #name of your dictionary\n",
    "        self.img_filenames = img_filenames #list of image filenames\n",
    "        self.num_words = num_words #the number of words\n",
    "        self.training_data = [] #this is the training data required by the K-Means algorithm\n",
    "        self.words = [] #list of words, which are the centroids of clusters\n",
    "    def learn(self):\n",
    "        sift = cv.xfeatures2d.SIFT_create()\n",
    "        num_keypoints = [] #this is used to store the number of keypoints in each image\n",
    "        #load training images and compute SIFT descriptors\n",
    "        for filename in self.img_filenames:\n",
    "            img = cv.imread(filename)\n",
    "            img_gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "            list_des = sift.detectAndCompute(img_gray, None)[1]\n",
    "            if list_des is None:\n",
    "                num_keypoints.append(0)\n",
    "            else:\n",
    "                num_keypoints.append(len(list_des))\n",
    "                for des in list_des:\n",
    "                    self.training_data.append(des)\n",
    "        #cluster SIFT descriptors using K-means algorithm\n",
    "        kmeans = KMeans(self.num_words)\n",
    "        kmeans.fit(self.training_data)\n",
    "        self.words = kmeans.cluster_centers_\n",
    "        #create word histograms for training images\n",
    "        training_word_histograms = [] #list of word histograms of all training images\n",
    "        index = 0\n",
    "        for i in range(0, len(self.img_filenames)):\n",
    "            #for each file, create a histogram\n",
    "            histogram = np.zeros(self.num_words, np.float32)\n",
    "            #if some keypoints exist\n",
    "            if num_keypoints[i] > 0:\n",
    "                for j in range(0, num_keypoints[i]):\n",
    "                    histogram[kmeans.labels_[j + index]] += 1\n",
    "                index += num_keypoints[i]\n",
    "                histogram /= num_keypoints[i]\n",
    "                training_word_histograms.append(histogram)\n",
    "        return training_word_histograms\n",
    "    def create_word_histograms(self, img_filenames):\n",
    "        sift = cv.xfeatures2d.SIFT_create()\n",
    "        histograms = []\n",
    "        for filename in img_filenames:\n",
    "            img = cv.imread(filename)\n",
    "            img_gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "            descriptors = sift.detectAndCompute(img_gray, None)[1]\n",
    "            histogram = np.zeros(self.num_words, np.float32) #word histogram for the input image\n",
    "            if descriptors is not None:\n",
    "                for des in descriptors:\n",
    "                #find the best matching word\n",
    "                    min_distance = 1111111 #this can be any large number\n",
    "                    matching_word_ID = -1 #initial matching_word_ID=-1 means no matching\n",
    "                \n",
    "                    for i in range(0, self.num_words): #search for the best matching word\n",
    "                        distance = np.linalg.norm(des - self.words[i])\n",
    "                        if distance < min_distance:\n",
    "                            min_distance = distance\n",
    "                            matching_word_ID = i\n",
    "                    histogram[matching_word_ID] += 1\n",
    "                histogram /= len(descriptors) #normalise histogram to frequencies\n",
    "            histograms.append(histogram)\n",
    "        return histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "106d0ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "foods = ['Cakes', 'Pasta', 'Pizza']\n",
    "path = 'FoodImages/'\n",
    "training_file_names = []\n",
    "training_food_labels = []\n",
    "for i in range(0, len(foods)):\n",
    "    sub_path = path + 'Train/' + foods[i] + '/'\n",
    "    sub_file_names = [os.path.join(sub_path, f) for f in os.listdir(sub_path)]\n",
    "    sub_food_labels = [i] * len(sub_file_names) #create a list of N elements, all are i\n",
    "    training_file_names += sub_file_names\n",
    "    training_food_labels += sub_food_labels\n",
    "#print(training_file_names)\n",
    "#print(training_food_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "354489ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = 50\n",
    "dictionary_name = 'food'\n",
    "dictionary = Dictionary(dictionary_name, training_file_names, num_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd6c87ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_word_histograms = dictionary.learn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b29add3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save dictionary\n",
    "with open('food_dictionary.dic', 'wb') as f: #'wb' is for binary write\n",
    "    pickle.dump(dictionary, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da07311b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('food_dictionary.dic', 'rb') as f: #'rb' is for binary read\n",
    "    dictionary = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad1a6207",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file_names = []\n",
    "test_food_labels = []\n",
    "for i in range(0, len(foods)):\n",
    "    sub_path = path + 'Test/' + foods[i] + '/'\n",
    "    sub_file_names = [os.path.join(sub_path, f) for f in os.listdir(sub_path)]\n",
    "    sub_food_labels = [i] * len(sub_file_names) #create a list of N elements, all are i\n",
    "    test_file_names += sub_file_names\n",
    "    test_food_labels += sub_food_labels\n",
    "\n",
    "word_histograms = dictionary.create_word_histograms(test_file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d85ccb50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct predictions for k 10 is 63\n",
      "Accuracy for k 10 is 0.7\n",
      "Confusion Matrix:\n",
      " [[15  6  9]\n",
      " [ 0 27  3]\n",
      " [ 0  9 21]]\n",
      "######################################################\n",
      "Correct predictions for k 15 is 61\n",
      "Accuracy for k 15 is 0.6777777777777778\n",
      "Confusion Matrix:\n",
      " [[14  6 10]\n",
      " [ 0 26  4]\n",
      " [ 0  9 21]]\n",
      "######################################################\n",
      "Correct predictions for k 20 is 64\n",
      "Accuracy for k 20 is 0.7111111111111111\n",
      "Confusion Matrix:\n",
      " [[14  9  7]\n",
      " [ 0 27  3]\n",
      " [ 0  7 23]]\n",
      "######################################################\n",
      "Correct predictions for k 25 is 60\n",
      "Accuracy for k 25 is 0.6666666666666666\n",
      "Confusion Matrix:\n",
      " [[14 10  6]\n",
      " [ 0 26  4]\n",
      " [ 0 10 20]]\n",
      "######################################################\n",
      "Correct predictions for k 30 is 59\n",
      "Accuracy for k 30 is 0.6555555555555556\n",
      "Confusion Matrix:\n",
      " [[11 13  6]\n",
      " [ 0 26  4]\n",
      " [ 0  8 22]]\n",
      "######################################################\n"
     ]
    }
   ],
   "source": [
    "k_list = [10,15,20,25,30]\n",
    "\n",
    "max_accuracy = 0\n",
    "best_k = k_list[0]\n",
    "\n",
    "for num_nearest_neighbours in k_list:\n",
    "    knn = KNeighborsClassifier(n_neighbors = num_nearest_neighbours)\n",
    "    knn.fit(training_word_histograms, training_food_labels)\n",
    "    \n",
    "    #test knn on all test images\n",
    "    predicted_food_labels = knn.predict(word_histograms)\n",
    "    #evaluation for accuracy and displayying confusion matrix\n",
    "    num_correct_predictions = np.sum(predicted_food_labels == test_food_labels)\n",
    "    recognition_acc = num_correct_predictions / (len(test_food_labels))\n",
    "    print(\"Correct predictions for k\", num_nearest_neighbours, \"is\", num_correct_predictions)\n",
    "    print(\"Accuracy for k\", num_nearest_neighbours, \"is\", recognition_acc)\n",
    "    cm = confusion_matrix(test_food_labels, predicted_food_labels)\n",
    "    \n",
    "    if (recognition_acc > max_accuracy):\n",
    "        max_accuracy = recognition_acc\n",
    "        best_k = num_nearest_neighbours\n",
    "        \n",
    "    print(\"Confusion Matrix:\\n\", cm)\n",
    "    print (\"######################################################\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff41358c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training SVM using C = 10\n",
      "Correct predictions for c 10 is 69\n",
      "Accuracy for c 10 is 0.7666666666666667\n",
      "Confusion Matrix:\n",
      " [[25  2  3]\n",
      " [ 0 24  6]\n",
      " [ 1  9 20]]\n",
      "######################################################\n",
      "Training SVM using C = 20\n",
      "Correct predictions for c 20 is 76\n",
      "Accuracy for c 20 is 0.8444444444444444\n",
      "Confusion Matrix:\n",
      " [[26  2  2]\n",
      " [ 0 23  7]\n",
      " [ 1  2 27]]\n",
      "######################################################\n",
      "Training SVM using C = 30\n",
      "Correct predictions for c 30 is 74\n",
      "Accuracy for c 30 is 0.8222222222222222\n",
      "Confusion Matrix:\n",
      " [[26  2  2]\n",
      " [ 0 23  7]\n",
      " [ 1  4 25]]\n",
      "######################################################\n",
      "Training SVM using C = 40\n",
      "Correct predictions for c 40 is 75\n",
      "Accuracy for c 40 is 0.8333333333333334\n",
      "Confusion Matrix:\n",
      " [[26  2  2]\n",
      " [ 0 23  7]\n",
      " [ 1  3 26]]\n",
      "######################################################\n",
      "Training SVM using C = 50\n",
      "Correct predictions for c 50 is 75\n",
      "Accuracy for c 50 is 0.8333333333333334\n",
      "Confusion Matrix:\n",
      " [[26  2  2]\n",
      " [ 0 23  7]\n",
      " [ 1  3 26]]\n",
      "######################################################\n"
     ]
    }
   ],
   "source": [
    "c_list = [10, 20, 30, 40, 50]\n",
    "max_accuracy = 0\n",
    "best_c_val = c_list[0]\n",
    "\n",
    "for c_val in c_list:\n",
    "    print (\"Training SVM using C =\", c_val)\n",
    "    svm_classifier = svm.SVC(C = c_val, #see slide 32 in week 4 lecture slides\n",
    "                             kernel = 'linear') #see slide 35 in week 4 lecture slides\n",
    "    svm_classifier.fit(training_word_histograms, training_food_labels)   \n",
    "    predicted_food_labels = svm_classifier.predict(word_histograms)\n",
    "    #evaluation for accuracy and displayying confusion matrix\n",
    "    num_correct_predictions = np.sum(predicted_food_labels == test_food_labels)\n",
    "    recognition_acc = num_correct_predictions / (len(test_food_labels))\n",
    "    print(\"Correct predictions for c\", c_val, \"is\", num_correct_predictions)\n",
    "    print(\"Accuracy for c\", c_val, \"is\", recognition_acc)\n",
    "    cm = confusion_matrix(test_food_labels, predicted_food_labels)\n",
    "    \n",
    "    if (recognition_acc > max_accuracy):\n",
    "        max_accuracy = recognition_acc\n",
    "        best_c_val = c_val\n",
    "        \n",
    "    print(\"Confusion Matrix:\\n\", cm)\n",
    "    print (\"######################################################\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74289d61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct predictions for n_estimators 50 is 66\n",
      "Accuracy for n_estimators 50 is 0.7333333333333333\n",
      "Confusion Matrix:\n",
      " [[21  6  3]\n",
      " [ 0 25  5]\n",
      " [ 2  8 20]]\n",
      "######################################################\n",
      "Correct predictions for n_estimators 100 is 59\n",
      "Accuracy for n_estimators 100 is 0.6555555555555556\n",
      "Confusion Matrix:\n",
      " [[17 11  2]\n",
      " [ 0 24  6]\n",
      " [ 2 10 18]]\n",
      "######################################################\n",
      "Correct predictions for n_estimators 150 is 63\n",
      "Accuracy for n_estimators 150 is 0.7\n",
      "Confusion Matrix:\n",
      " [[17  5  8]\n",
      " [ 0 23  7]\n",
      " [ 2  5 23]]\n",
      "######################################################\n",
      "Correct predictions for n_estimators 200 is 64\n",
      "Accuracy for n_estimators 200 is 0.7111111111111111\n",
      "Confusion Matrix:\n",
      " [[20  6  4]\n",
      " [ 0 23  7]\n",
      " [ 2  7 21]]\n",
      "######################################################\n",
      "Correct predictions for n_estimators 250 is 64\n",
      "Accuracy for n_estimators 250 is 0.7111111111111111\n",
      "Confusion Matrix:\n",
      " [[18  7  5]\n",
      " [ 0 23  7]\n",
      " [ 1  6 23]]\n",
      "######################################################\n"
     ]
    }
   ],
   "source": [
    "n_estimators_list = [50, 100, 150, 200, 250]\n",
    "max_accuracy = 0\n",
    "best_n_estimators = n_estimators_list[0]\n",
    "\n",
    "for n_estimators in n_estimators_list:\n",
    "    adb_classifier = AdaBoostClassifier(n_estimators = n_estimators, random_state = 42)\n",
    "    adb_classifier.fit(training_word_histograms, training_food_labels)\n",
    "    predicted_food_labels = adb_classifier.predict(word_histograms)\n",
    "    #evaluation for accuracy and displayying confusion matrix\n",
    "    num_correct_predictions = np.sum(predicted_food_labels == test_food_labels)\n",
    "    recognition_acc = num_correct_predictions / (len(test_food_labels))\n",
    "    print(\"Correct predictions for n_estimators\", n_estimators, \"is\", num_correct_predictions)\n",
    "    print(\"Accuracy for n_estimators\", n_estimators, \"is\", recognition_acc)\n",
    "    cm = confusion_matrix(test_food_labels, predicted_food_labels)\n",
    "    \n",
    "    if (recognition_acc > max_accuracy):\n",
    "        max_accuracy = recognition_acc\n",
    "        best_n_estimators = n_estimators\n",
    "        \n",
    "    print(\"Confusion Matrix:\\n\", cm)\n",
    "    print (\"######################################################\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9507c3a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best k for KNN is:  20\n",
      "The best c for SVM is:  20\n",
      "The best n_estimators for AdaBoostClassifier is:  50\n"
     ]
    }
   ],
   "source": [
    "print (\"The best k for KNN is: \", best_k)\n",
    "print (\"The best c for SVM is: \", best_c_val)\n",
    "print (\"The best n_estimators for AdaBoostClassifier is: \", best_n_estimators)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55fedeba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
