{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76837701",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:219: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n",
      "C:\\Users\\singh\\anaconda3\\lib\\site-packages\\pydub\\utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import glob\n",
    "import librosa\n",
    "from pydub import AudioSegment\n",
    "from pydub.utils import mediainfo\n",
    "from sklearn import preprocessing\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7c04a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mfcc_extraction(audio_filename, #.wav filename\n",
    "                    hop_duration, #hop_length in seconds, e.g., 0.015s (i.e., 15ms)\n",
    "                    num_mfcc #number of mfcc features\n",
    "                   ):\n",
    "    speech = AudioSegment.from_wav(audio_filename) #Read audio data from file\n",
    "    samples = speech.get_array_of_samples() #samples x(t)\n",
    "    sampling_rate = speech.frame_rate #sampling rate f\n",
    "    mfcc = librosa.feature.mfcc(\n",
    "    y = np.float32(samples),\n",
    "    sr = sampling_rate,\n",
    "    hop_length = int(sampling_rate * hop_duration),\n",
    "    n_mfcc = num_mfcc)\n",
    "    return mfcc.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c498c8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def learningGMM(features, #list of feature vectors, each feature vector is an array\n",
    "                n_components, #the number of components\n",
    "                max_iter #maximum number of iterations\n",
    "               ):\n",
    "    gmm = GaussianMixture(n_components = n_components, max_iter = max_iter)\n",
    "    gmm.fit(features)\n",
    "    return gmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a065cac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Anthony', 'AppleEater', 'Ara', 'Argail', 'Ariyan', 'Arjuan', 'Artem', 'Arthur', 'Artk', 'Arun', 'Arvala', 'Asalkeld', 'Asladic', 'Asp', 'Azmisov', 'B', 'Bachroxx', 'Bae', 'Bahoke', 'Bareford', 'Bart', 'Bassel', 'Beady', 'Beez', 'BelmontGuy']\n"
     ]
    }
   ],
   "source": [
    "path = 'SpeakerData/'\n",
    "speakers = os.listdir(path + 'Train/')\n",
    "print(speakers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6aa721a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this list is used to store the MFCC features of all training data of all speakers\n",
    "mfcc_all_speakers = []\n",
    "hop_duration = 0.015 #15ms\n",
    "num_mfcc = 12\n",
    "for s in speakers:\n",
    "    sub_path = path + 'Train/' + s + '/'\n",
    "    sub_file_names = [os.path.join(sub_path, f) for f in os.listdir(sub_path)]\n",
    "    mfcc_one_speaker = np.asarray(())\n",
    "    for fn in sub_file_names:\n",
    "        mfcc_one_file = mfcc_extraction(fn, hop_duration, num_mfcc)\n",
    "        if mfcc_one_speaker.size == 0:\n",
    "            mfcc_one_speaker = mfcc_one_file\n",
    "        else:\n",
    "            mfcc_one_speaker = np.vstack((mfcc_one_speaker, mfcc_one_file))\n",
    "    mfcc_all_speakers.append(mfcc_one_speaker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59cbfa7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(speakers)):\n",
    "    with open('TrainingFeatures/' + speakers[i] + '_mfcc.fea','wb') as f:\n",
    "        pickle.dump(mfcc_all_speakers[i], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ced39c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = 5\n",
    "max_iter = 50\n",
    "gmms = [] #list of GMMs, each is for a speaker\n",
    "for i in range(0, len(speakers)):\n",
    "    gmm = learningGMM(mfcc_all_speakers[i],\n",
    "                      n_components,\n",
    "                      max_iter)\n",
    "    gmms.append(gmm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "816e3223",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(speakers)):\n",
    "    with open('Models/' + speakers[i] + '.gmm', 'wb') as f: #'wb' is for binary write\n",
    "        pickle.dump(gmms[i], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9f4e494",
   "metadata": {},
   "outputs": [],
   "source": [
    "gmms = []\n",
    "for i in range(len(speakers)):\n",
    "    with open('Models/' + speakers[i] + '.gmm', 'rb') as f: #'wb' is for binary write\n",
    "        gmm = pickle.load(f)\n",
    "        gmms.append(gmm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "817abcf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "hop_duration = 0.015 #15ms\n",
    "num_mfcc = 12\n",
    "def speaker_recognition(audio_file_name, gmms):\n",
    "    speaker_id = 0 #you need to calculate this\n",
    "    score_list = []\n",
    "    for i, gmm in enumerate(gmms):\n",
    "        mfcc_test = mfcc_extraction(audio_file_name, hop_duration, num_mfcc)\n",
    "        score_list.append((i,gmms[i].score(mfcc_test)))\n",
    "    max_element = max(score_list, key=lambda x:x[1])\n",
    "    #print(\"Max: \", max_element)\n",
    "    #print(\"Max Index: \", max_element[0])\n",
    "    speaker_id = max_element[0]\n",
    "    return speaker_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7ea8595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ara\n"
     ]
    }
   ],
   "source": [
    "speaker_id = speaker_recognition('SpeakerData/Test/Ara/a0522.wav', gmms)\n",
    "print(speakers[speaker_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5162656",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 175/175 [01:33<00:00,  1.88it/s]\n"
     ]
    }
   ],
   "source": [
    "files = glob.glob(\"SpeakerData/Test/*/*\")\n",
    "y_true = []\n",
    "y_pred = []\n",
    "for file in tqdm(files):\n",
    "    #print (\"Processing file:\", file)\n",
    "    #print (os.path.basename(os.path.dirname(file)))\n",
    "    true_label = os.path.basename(os.path.dirname(file))\n",
    "    speaker_id = speaker_recognition(file, gmms)\n",
    "    pred_label = speakers[speaker_id]\n",
    "    y_true.append(true_label)\n",
    "    y_pred.append(pred_label)\n",
    "    #print(\"True: \", true_label, \" Pred:\", pred_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40fe5b73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     Anthony       1.00      0.14      0.25         7\n",
      "  AppleEater       1.00      1.00      1.00         7\n",
      "         Ara       1.00      1.00      1.00         7\n",
      "      Argail       1.00      1.00      1.00         7\n",
      "      Ariyan       1.00      1.00      1.00         7\n",
      "      Arjuan       1.00      1.00      1.00         7\n",
      "       Artem       1.00      1.00      1.00         7\n",
      "      Arthur       0.39      1.00      0.56         7\n",
      "        Artk       1.00      1.00      1.00         7\n",
      "        Arun       1.00      1.00      1.00         7\n",
      "      Arvala       1.00      1.00      1.00         7\n",
      "    Asalkeld       1.00      1.00      1.00         7\n",
      "     Asladic       1.00      1.00      1.00         7\n",
      "         Asp       1.00      1.00      1.00         7\n",
      "     Azmisov       1.00      1.00      1.00         7\n",
      "           B       1.00      1.00      1.00         7\n",
      "    Bachroxx       1.00      1.00      1.00         7\n",
      "         Bae       1.00      1.00      1.00         7\n",
      "      Bahoke       1.00      0.86      0.92         7\n",
      "    Bareford       1.00      1.00      1.00         7\n",
      "        Bart       1.00      0.29      0.44         7\n",
      "      Bassel       0.88      1.00      0.93         7\n",
      "       Beady       1.00      1.00      1.00         7\n",
      "        Beez       1.00      1.00      1.00         7\n",
      "  BelmontGuy       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           0.93       175\n",
      "   macro avg       0.97      0.93      0.92       175\n",
      "weighted avg       0.97      0.93      0.92       175\n",
      "\n",
      "Confusion Matrix\n",
      " [[1 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 7 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 7 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 7 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 7 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 7 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 7 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 7 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 7 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 7 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 7 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 7 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 7 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 7 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 7 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 7 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 7 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 7 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 6 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 7 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 5 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 7 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 7 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 7 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 7]]\n",
      "Overall Accuracy:\n",
      " 0.9314285714285714\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_true, y_pred)\n",
    "print(\"Classification Report\\n\", classification_report(y_true, y_pred))\n",
    "print(\"Confusion Matrix\\n\", cm)\n",
    "print(\"Overall Accuracy:\\n\", accuracy_score(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec8fa05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
