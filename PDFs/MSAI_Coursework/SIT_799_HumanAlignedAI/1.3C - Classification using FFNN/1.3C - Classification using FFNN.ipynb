{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QPYLmAm2y374"
   },
   "source": [
    "Welcome to your assignment this week! \n",
    "\n",
    "\n",
    "# Classification task\n",
    "\n",
    "In this task you are asked to build a simple Feed Forward Neural Network, train it and test it!\n",
    "\n",
    "\n",
    "**After this assignment you will be able to:**\n",
    "\n",
    "- Load a dataset.\n",
    "- Train a Feed Forward Neural Network.\n",
    "- Test a Feed Forward Neural Network.\n",
    "\n",
    "Let's get started! Run the following cell to install all the packages you will need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "MwVJpPoAy374"
   },
   "outputs": [],
   "source": [
    "#!pip install numpy\n",
    "#!pip install keras\n",
    "#!pip install tensorflow\n",
    "#!pip install pandas\n",
    "#!pip install matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if you are using GoogleColab, please install the following packages and mount your Google drive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !apt-get install texlive-xetex texlive-fonts-recommended texlive-generic-recommended  2> /dev/null  > /dev/null \n",
    "# !apt-get install pandoc 2> /dev/null  > /dev/null \n",
    "\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x67z_R3_y375"
   },
   "source": [
    "Run the following cell to load the packages you will need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "0K67BsATy375"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wiJC_sYzy375"
   },
   "source": [
    "The dataset we will use consists of 4500 examples with 512 features. A label is given for each example to indicate positive and negative instances.\n",
    "\n",
    "Let's read the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Ltzm-RMuy376"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.csv')\n",
    "df.set_index('id', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NnCcO3a6y377"
   },
   "source": [
    "Now, let's split the data into training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "7WUzliVZy377"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df.index.values,\n",
    "    df.label.values,\n",
    "    test_size=0.15,\n",
    "    random_state=17,\n",
    "    stratify=df.label.values\n",
    ")\n",
    "df['data_type'] = ['note_set']*df.shape[0]\n",
    "df.loc[X_train, 'data_type'] = 'train'\n",
    "df.loc[X_test, 'data_type'] = 'test'\n",
    "\n",
    "## The data to use:\n",
    "\n",
    "X_train = df[df['data_type']=='train'].iloc[:,:512].values\n",
    "X_test = df[df['data_type']=='test'].iloc[:,:512].values\n",
    "#y_train = df[df['data_type']=='train'].iloc[:,512:513].values\n",
    "y_train = df[df['data_type']=='train']['label'].to_list()\n",
    "y_train = np.array(y_train)\n",
    "#y_test = df[df['data_type']=='test'].iloc[:,512:513].values\n",
    "y_test = df[df['data_type']=='test']['label'].to_list()\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3825, 512)\n",
      "(3825,)\n",
      "(675, 512)\n",
      "(675,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3825, 512)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Ga4DGNTy377"
   },
   "source": [
    "# Task 1\n",
    "\n",
    "Build a Feed Forward Neural Network to address this classification task using the Keras framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "i8d-psy2y378"
   },
   "outputs": [],
   "source": [
    "# START YOUR CODE HERE\n",
    "model = Sequential([\n",
    "  Dense(128, activation='relu', input_shape=(512,)),\n",
    "  Dense(128, activation='relu'),\n",
    "  Dense(1, activation='softmax'),\n",
    "])\n",
    "model.compile(\n",
    "  optimizer='adam',\n",
    "  loss='categorical_crossentropy',\n",
    "  metrics=['accuracy', 'Precision', 'Recall'],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xwfUGs9Ty378"
   },
   "source": [
    "# Training\n",
    "\n",
    "Now, let's start our training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Fn7fPEvTy378"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "60/60 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 2/200\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 3/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 4/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 5/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 6/200\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 7/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 8/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 9/200\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 10/200\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 11/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 12/200\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 13/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 14/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 15/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 16/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 17/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 18/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 19/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 20/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 21/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 22/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 23/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 24/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 25/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 26/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 27/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 28/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 29/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 30/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 31/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 32/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 33/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 34/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 35/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 36/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 37/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 38/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 39/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 40/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 41/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 42/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 43/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 44/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 45/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 46/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 47/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 48/200\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 49/200\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 50/200\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 51/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 52/200\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 53/200\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 54/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 55/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 56/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 57/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 58/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 59/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 60/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 61/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 62/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 63/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 64/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 65/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 66/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 67/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 68/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 69/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 70/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 71/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 72/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 73/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 74/200\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 75/200\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 76/200\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 77/200\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 78/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 79/200\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 80/200\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 81/200\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 82/200\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 83/200\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 84/200\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 85/200\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 86/200\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 87/200\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 88/200\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 89/200\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 90/200\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 91/200\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 92/200\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 93/200\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 94/200\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 95/200\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 96/200\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 97/200\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 98/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 99/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 100/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 101/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 102/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 103/200\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 104/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 105/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 106/200\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 107/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 108/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 109/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 110/200\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 111/200\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 112/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 113/200\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 114/200\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 115/200\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 116/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 117/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 118/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 119/200\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 120/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 121/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 122/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 123/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 124/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 125/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 126/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 127/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 128/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 129/200\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 130/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 131/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 132/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 133/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 134/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 135/200\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 136/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 137/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 138/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 139/200\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 140/200\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 141/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 142/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 143/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 144/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 145/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 146/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 147/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 148/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 149/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 150/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 151/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 152/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 153/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 154/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 155/200\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 156/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 157/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 158/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 159/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 160/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 161/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 162/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 163/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 164/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 165/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 166/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 167/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 168/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 169/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 170/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 171/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 172/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 173/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 174/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 175/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 176/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 177/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 178/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 179/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 180/200\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 181/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 182/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 183/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 184/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 185/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 186/200\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 187/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 188/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 189/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 190/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 191/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 192/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 193/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 194/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 195/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 196/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 197/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 198/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 199/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n",
      "Epoch 200/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6348 - precision: 0.6348 - recall: 1.0000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=200, batch_size=64, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "IMYgz8nAy378"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = history.history['accuracy']\n",
    "loss = history.history['loss']\n",
    "epochs = range(len(acc))\n",
    "plt.plot(epochs, acc, 'b', label='Training accuracy')\n",
    "plt.title('Training accuracy')\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'b', label='Training Loss')\n",
    "plt.title('Training loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ewyOTi3Ay378"
   },
   "source": [
    "# Task 2\n",
    "\n",
    "Test the model on the test set and report Precision, Recall, F1-Score, and Accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "f7IzXUJBy379"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 2ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      1.00      0.54       247\n",
      "           1       1.00      0.00      0.00       428\n",
      "\n",
      "    accuracy                           0.37       675\n",
      "   macro avg       0.68      0.50      0.27       675\n",
      "weighted avg       0.77      0.37      0.20       675\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# START YOUR CODE HERE\n",
    "from sklearn.metrics import classification_report\n",
    "y_pred = model.predict(X_test, verbose=1)\n",
    "y_pred_bool = np.argmax(y_pred, axis=1)\n",
    "print(classification_report(y_test, y_pred_bool, zero_division=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export your notebook to a pdf document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook ./1.3C - Classification using FFNN.ipynb to pdf\n",
      "[NbConvertApp] Writing 66511 bytes to 1.3C - Classification using FFNN.pdf\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to pdf \"./1.3C - Classification using FFNN.ipynb\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E6vau2ijy379"
   },
   "source": [
    "# Congratulations!\n",
    "\n",
    "You've come to the end of this assignment, and you have built your first neural network. \n",
    "\n",
    "Congratulations on finishing this notebook! \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "1.3C - Classification using FFNN.ipynb",
   "provenance": []
  },
  "coursera": {
   "course_slug": "nlp-sequence-models",
   "graded_item_id": "8hb5s",
   "launcher_item_id": "5NrJ6"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
